# Introduction to responsible to AI:

**Manny, Security Engineer at Google**:
- Manny introduces the topic of responsible AI, highlighting its importance.
- The goal is to understand why AI principles are essential, identify the need for responsible AI, and recognize its impact on all project stages.

### Daily Interactions with AI

**Examples of AI Use**:
- AI is prevalent in everyday tasks like predicting traffic, weather, and recommending TV shows.
- As AI becomes more integrated into technology, non-AI-enabled technologies start to seem outdated.

**AI Advancements**:
- AI systems are rapidly evolving, enabling computers to perform tasks like seeing, understanding, and interacting with the world.
- These advancements, while impressive, are not without their flaws.

### Importance of Responsible AI

**Infallibility of AI**:
- Despite advancements, AI is not perfect.
- Developing responsible AI involves understanding possible issues, limitations, and unintended consequences.

**Reflection of Society**:
- Technology mirrors societal issues, and without good practices, AI may replicate and amplify existing biases.
- This makes responsible AI practices crucial.

### Defining Responsible AI

**No Universal Definition**:
- There isn't a single definition or checklist for responsible AI.
- Organizations develop their own AI principles based on their mission and values.

**Common Themes in AI Principles**:
- Despite unique principles, common themes include transparency, fairness, accountability, and privacy.

### Google's Approach to Responsible AI

**AI Principles at Google**:
- Google aims for AI that is built for everyone, is accountable, respects privacy, and is driven by scientific excellence.
- They have developed AI principles, practices, governance processes, and tools to embody these values.

**Responsibility by Design**:
- Responsibility is integrated into Google's products and organization.
- AI principles serve as a framework for responsible decision-making.

### Human Role in AI Development

**Human Involvement**:
- Humans design and build AI systems and decide their usage.
- Decisions made during AI development reflect personal values and require ethical consideration.

### Guiding Principles and Practices

**Google's Seven AI Principles**:
1. **Social Benefit**: AI projects should consider social and economic factors, proceeding only if benefits outweigh risks.
2. **Avoiding Bias**: AI should not create or reinforce unfair biases, especially related to sensitive characteristics.
3. **Safety**: AI should be developed and tested for safety, avoiding unintended harmful results.
4. **Accountability**: AI systems should allow for feedback, explanations, and appeal.
5. **Privacy**: AI should incorporate privacy design principles, providing transparency and control over data use.
6. **Scientific Excellence**: AI should uphold high standards of scientific rigor and responsibly share knowledge.
7. **Responsible Use**: AI should be used for applications that align with these principles.

**Prohibited AI Applications**:
- Google will not develop AI for harmful technologies, weapons, surveillance violating norms, or applications against international law.

### Continuous Improvement

**AI Principles as a Foundation**:
- These principles are a starting point, ensuring responsible AI development and ethical decision-making.
- They guide AI projects, making sure they align with societal values and ethical standards.

### Practical Implementation

**Product Development and Trust**:
- Building responsibility into AI deployments creates better models and builds trust with customers.
- Trust is crucial for successful AI deployments.

**Robust Processes and Assessments**:
- Assessments and reviews ensure projects align with AI principles.
- A robust process instills trust, even if not everyone agrees with every decision.

### Conclusion

**AI Principles in Action**:
- AI principles guide the development and deployment of AI, ensuring it is beneficial and ethical.
- The principles help navigate complex decisions, maintaining ethical standards and societal trust.

### Summary of the Seven AI Principles

1. **AI Should Be Socially Beneficial**: Projects should consider social and economic impacts, proceeding only if benefits outweigh risks.
2. **AI Should Avoid Creating or Reinforcing Unfair Bias**: Projects should avoid unjust effects on people based on sensitive characteristics.
3. **AI Should Be Built and Tested for Safety**: Strong safety practices should be in place to avoid unintended harmful results.
4. **AI Should Be Accountable to People**: Systems should allow for feedback, explanations, and appeals.
5. **AI Should Incorporate Privacy Design Principles**: AI should include privacy safeguards, transparency, and control over data use.
6. **AI Should Uphold High Standards of Scientific Excellence**: AI should be developed with scientific rigor and shared knowledge.
7. **AI Should Be Made Available for Uses that Accord with These Principles**: AI should be used responsibly, avoiding harmful applications.

### Summary of Prohibited AI Applications

- **Technologies Causing Harm**: AI that likely causes overall harm.
- **Weapons**: AI for weapons or technologies facilitating injury.
- **Surveillance Violating Norms**: AI for surveillance against internationally accepted norms.
- **Violating International Law**: AI against widely accepted international laws and human rights.

### Final Thoughts

**AI Principles as a Foundation**:
- AI principles are not direct answers but a foundation for ethical AI development.
- They require ongoing conversations and considerations for ethical AI deployment.

**Ethical Development**:
- Developing responsible AI ensures it is beneficial, ethical, and trusted.
- It is crucial for AI's positive impact on society.

This detailed breakdown covers the core ideas and key points from the provided text, ensuring a comprehensive understanding of the concepts discussed.


https://www.cloudskillsboost.google/focuses/2794?parent=catalog&path=17