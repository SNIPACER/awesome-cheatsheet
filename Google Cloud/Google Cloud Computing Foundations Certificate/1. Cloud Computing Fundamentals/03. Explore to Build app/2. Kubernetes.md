# LAB - Google Kubernetes Engine: Qwik Start

- [Google Kubernetes Engine (GKE)](https://cloud.google.com/kubernetes-engine) provides a managed environment for deploying, managing, and scaling your containerized applications using Google infrastructure.
- The GKE environment consists of multiple machines (specifically [Compute Engine](https://cloud.google.com/compute) instances) grouped to form a [container cluster](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture).

## Cluster orchestration with Google Kubernetes Engine
- Google Kubernetes Engine (GKE) clusters are powered by the Kubernetes open source cluster management system. Kubernetes provides the mechanisms through which you interact with your container cluster.
- You use Kubernetes commands and resources to deploy and manage your applications, perform administrative tasks, set policies, and monitor the health of your deployed workloads.
- Kubernetes draws on the same design principles that run popular Google services and provides the same benefits: automatic management, monitoring and liveness probes for application containers, automatic scaling, rolling updates, and more.
- When you run your applications on a container cluster, you're using technology based on Google's 10+ years of experience with running production workloads in containers.

## Kubernetes on Google Cloud

- When you run a GKE cluster, you also gain the benefit of advanced cluster management features that Google Cloud provides. These include:

- [**Load balancing**](https://cloud.google.com/compute/docs/load-balancing-and-autoscaling) for Compute Engine instances
- [**Node pools**](https://cloud.google.com/kubernetes-engine/docs/node-pools) to designate subsets of nodes within a cluster for additional flexibility
- [**Automatic scaling**](https://cloud.google.com/kubernetes-engine/docs/cluster-autoscaler) of your cluster's node instance count
- [**Automatic upgrades**](https://cloud.google.com/kubernetes-engine/docs/node-auto-upgrade) for your cluster's node software
- [**Node auto-repair**](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-repair) to maintain node health and availability
- [**Logging and Monitoring**](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-repair) with Cloud Monitoring for visibility into your cluster

## Task 1. Set a default compute zone

- Your [compute zone](https://cloud.google.com/compute/docs/regions-zones/#available) is an approximate regional location in which your clusters and their resources live.
- For example, us-central1-a is a zone in the us-central1 region.

1. Set the default compute region: `gcloud config set compute/region <REGION>`
2. Set the default compute zone: `gcloud config set compute/zone <ZONE>`

## Task 2. Create a GKE cluster

- A cluster consists of at least one cluster master machine and multiple worker machines called nodes. Nodes are Compute Engine virtual machine (VM) instances that run the Kubernetes processes necessary to make them part of the cluster.

<table style="width: 70%">
<tr>
<td>

**Note**: Cluster names must start with a letter and end with an alphanumeric, and cannot be longer than 40 characters.

</td>
</tr>
</table>


1. Create a cluster: `gcloud container clusters create --machine-type=e2-medium --zone=ZONE lab-cluster`


## Task 3. Get authentication credentials for the cluster

- After creating your cluster, you need authentication credentials to interact with it.

1. Authenticate with the cluster: `gcloud container clusters get-credentials lab-cluster`


## Task 4. Deploy an application to the cluster

- You can now deploy a containerized application to the cluster. For this lab, you'll run `hello-app` in your cluster.

- GKE uses Kubernetes objects to create and manage your cluster's resources.
- Kubernetes provides the Deployment object for deploying stateless applications like web servers.
- Service objects define rules and load balancing for accessing your application from the internet.

1. To create a new Deployment hello-server from the hello-app container image, run the following kubectl create command:
   1. `kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:1.0`
      1. This Kubernetes command creates a deployment object that represents `hello-server`.
      2. In this case, `--image` specifies a container image to deploy. The command pulls the example image from a [Container Registry](https://cloud.google.com/container-registry/docs) bucket. `gcr.io/google-samples/hello-app:1.0` indicates the specific image version to pull.
      3. If a version is not specified, the latest version is used.
2. To create a Kubernetes Service, which is a Kubernetes resource that lets you expose your application to external traffic, run the following kubectl expose command:
   1. `kubectl expose deployment hello-server --type=LoadBalancer --port 8080`
      1. `--port` specifies the port that the container exposes. 
      2. `type="LoadBalancer"` creates a Compute Engine load balancer for your container.
3. To inspect the hello-server Service, run kubectl get:
   1. `kubectl get service`
4. To view the application from your web browser
   1. `http://[EXTERNAL-IP]:8080`


## Task 5. Deleting the cluster

1. To **delete** the cluster, run the following command:
   1. `gcloud container clusters delete lab-cluster`
   2. Press `Y` to confirm.


# Cloud Run - Manage serverless computing with cloud run


- A fully managed serverless platform for developing and deploying scalable containerized applications.

## Cloud Run is managed serverless computing

- A managed compute platform that can run stateless containers.
- Serverless, removing the need for infrastructure management.
- Built on Knative, an open API and runtime environment built on Kubernetes.
- Can automatically scale up and down from zero almost instantaneously, charging only for the resources used.

![alt text](./assets/cloud%20run%20workflow.png)

![alt text](./assets/cloud%20run%20workflow-2.png)

![alt text](./assets/clud%20run%20billing.png)


# Quiz

1. Which compute service would be considered IaaS?

- [ ] Cloud Functions
- [ ] Google Kubernetes Engine
- [x] Compute Engine
- [ ] App Engine

2. What is the Compute Engine feature that allows VMs to be added to or subtracted from an application based on load metrics?

- [ ] Persistent disks
- [x] Autoscaling
- [ ] Load balancing
- [ ] Network time protocol (NTP)

3. Which of these is a managed compute platform that lets you run stateless containers through web requests or Pub/Sub events?

- [ ] App Engine
- [ ] Cloud Functions
- [ ] Cloud Run
- [ ] Google Kubernetes Engine

4. Which App Engine environment is based on preconfigured container instances?

- [x] Standard environment
- [ ] Flexible environment
- [ ] Both standard and flexible environments

7. Which of these is a lightweight, fully managed serverless execution environment for building and connecting cloud services?

- [ ] App Engine
- [ ] Compute Engine
- [ ] Google Kubernetes Engine
- [x] Cloud Functions

8. Which of these is a managed environment for deploying containerized apps?

- [x] Google Kubernetes Engine
- [ ] App Engine
- [ ] Cloud Functions
- [ ] Cloud Run